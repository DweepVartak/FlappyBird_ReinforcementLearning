{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import mss\n",
    "import mss.tools\n",
    "from gymnasium import Env\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from paddleocr import PaddleOCR\n",
    "import pydirectinput\n",
    "import pygetwindow as gw\n",
    "import ctypes\n",
    "import logging\n",
    "import os\n",
    "import gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('ppocr').setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class FlappyBirdEnv(Env):\n",
    "    def __init__(self,monitor_index=1):\n",
    "        super().__init__()\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(1,144,192) , dtype=np.uint8)\n",
    "        self.action_space = spaces.Discrete(2)  # 0: No Jump, 1: Jump\n",
    "        \n",
    "        #self.step_count=1\n",
    "        self.cnt=1\n",
    "        self.cap = mss.mss()\n",
    "        self.monitor = self.cap.monitors[monitor_index]\n",
    "        self.roi = {'top': 150, 'left': 820, 'width': 960, 'height': 720}\n",
    "        self.done_location = {'top':170, 'left':750, 'width':430, 'height':110}\n",
    "        self.ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "\n",
    "        self.screen_top_boundary = 150\n",
    "        self.screen_bottom_boundary = 720\n",
    "    \n",
    "    def capture_screen(self):\n",
    "        screenshot = self.cap.grab(self.roi)\n",
    "        frame = np.array(screenshot)\n",
    "        return frame\n",
    "    \n",
    "    def capture_done(self):\n",
    "        screenshot = self.cap.grab(self.done_location)\n",
    "        frame = np.array(screenshot)\n",
    "        return frame\n",
    "\n",
    "    def detect_contours(self, frame):\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        return thresh, contours\n",
    "\n",
    "    def reset(self, seed=None, return_info=False, options=None):\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        if self.cnt==1:\n",
    "            game_window = gw.getWindowsWithTitle('Flappy Bird')[0]\n",
    "            ctypes.windll.user32.SetForegroundWindow(game_window._hWnd)\n",
    "            self.cnt = self.cnt+1\n",
    "        \n",
    "        info={}\n",
    "\n",
    "        time.sleep(1.5)\n",
    "        x, y = 970, 805\n",
    "        # Move the mouse to the coordinates and click\n",
    "        pydirectinput.moveTo(x, y)\n",
    "        pydirectinput.click()\n",
    "        #pydirectinput.press('space')\n",
    "        return self.get_observation(),info\n",
    "    \n",
    "    def step(self, action):\n",
    "        \n",
    "            # Action key -> 0=noJummp , 1=Jump\n",
    "        action_map = {\n",
    "            0: 'no_jump',\n",
    "            1: 'd'#jump\n",
    "        }\n",
    "        if action != 0:\n",
    "            pydirectinput.press(action_map[action])\n",
    "\n",
    "        truncated = False\n",
    "        done , done_cap = self.get_done() # check if done\n",
    "        new_observation =  self.get_observation() #get new observ\n",
    "        #Reward\n",
    "        reward = 1\n",
    "        frame = self.capture_screen()\n",
    "        _, contours = self.detect_contours(frame)\n",
    "        bird_position = self.get_bird_position(contours)\n",
    "        if bird_position is not None:\n",
    "            _, bird_y, _, _ = bird_position\n",
    "            if bird_y < self.screen_top_boundary or bird_y > self.screen_bottom_boundary:\n",
    "                reward -= 2\n",
    "\n",
    "        info={}#.....streambaseline needs this      \n",
    "        return new_observation, reward, done, truncated, info\n",
    "\n",
    "    def get_bird_position(self, contours):\n",
    "        # Method to find the bird based on size and position\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            # Check if the contour matches the bird's size and x-coordinate range\n",
    "            if w <= 100 and h <= 100 and 50 <= x <= 250:\n",
    "                # Draw a green rectangle around the detected bird\n",
    "                 #cv2.rectangle(self.frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                # Return the bird's position (you can return other values if needed)\n",
    "                return (x, y, w, h)\n",
    "        # Return None if no bird is found\n",
    "        return None\n",
    "\n",
    "    def render(self):\n",
    "        #plt.imshow('Game', np.array(self.get_observation()))\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        #cv2.destroyAllWindows()\n",
    "        pass\n",
    "    \n",
    "    def get_observation(self):\n",
    "        screen = self.capture_screen()\n",
    "        gray = cv2.cvtColor(screen, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        screen_resized = cv2.resize(gray, (192, 144))  # Resize to (58, 48)\n",
    "        _, thresh = cv2.threshold(screen_resized, 160, 255, cv2.THRESH_BINARY_INV)  # Thresholding\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        mask = np.ones_like(screen_resized) * 255  # Create mask\n",
    "        cv2.drawContours(mask, contours, -1, (0), thickness=cv2.FILLED)  # Draw contours\n",
    "        channel = np.expand_dims(mask, axis=0)  # Add channel dimension\n",
    "        return channel\n",
    "\n",
    "\n",
    "\n",
    "    def get_done(self):\n",
    "        done_cap = self.capture_done() \n",
    "        target_bgr = [82, 159, 250]  # The BGR values you want to check\n",
    "        target_coords_1 = (50, 50)   # Coordinate 1 for color check\n",
    "        target_coords_2 = (350, 50)  # Coordinate 2 for color check\n",
    "        time.sleep(0.1)\n",
    "        pixel_value_1 = done_cap[target_coords_1[1], target_coords_1[0]]\n",
    "        pixel_value_2 = done_cap[target_coords_2[1], target_coords_2[0]]\n",
    "        \n",
    "        done = all(pixel_value_1[:3] == target_bgr) and all(pixel_value_2[:3] == target_bgr)\n",
    "\n",
    "        return done, done_cap\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FlappyBirdEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward for episode 1 is 0\n",
      "Total Reward for episode 2 is 11\n",
      "Total Reward for episode 3 is 0\n",
      "Total Reward for episode 4 is 11\n",
      "Total Reward for episode 5 is 6\n",
      "Total Reward for episode 6 is 1\n",
      "Total Reward for episode 7 is 2\n",
      "Total Reward for episode 8 is 2\n",
      "Total Reward for episode 9 is 2\n",
      "Total Reward for episode 10 is 2\n"
     ]
    }
   ],
   "source": [
    "for episode in range(10): \n",
    "    obs = env.reset()\n",
    "    done = False  \n",
    "    total_reward   = 0\n",
    "    while not done:  \n",
    "        obs, reward,  done, truncated,info =  env.step(env.action_space.sample())\n",
    "        total_reward  += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode+1, total_reward))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "CUDA Version: 11.8\n",
      "Device Name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(\"Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from stable_baselines3.common import env_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True\n",
    "    \n",
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callback = TrainAndLoggingCallback(check_freq=1000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FlappyBirdEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = DQN('CnnPolicy', env,device = 'cuda', tensorboard_log=LOG_DIR, verbose=1, buffer_size=60000, learning_starts=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=80000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testingggg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "obs[0].shape\n",
    "obs = np.expand_dims(obs[0], axis=0)  # This adds a batch dimension, so shape becomes (1, 1, 48, 58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Predict the action\n",
    "action, _ = model.predict(obs)\n",
    "action\n",
    "model.predict(obs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = DQN.load(\"train/best_model_52000\", env=env, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(model.replay_buffer.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward for episode 1 is 2\n",
      "Total Reward for episode 2 is 25\n",
      "Total Reward for episode 3 is 37\n",
      "Total Reward for episode 4 is 56\n",
      "Total Reward for episode 5 is 176\n"
     ]
    }
   ],
   "source": [
    "for episode in range(5): \n",
    "    obs = env.reset()\n",
    "    obs = np.expand_dims(obs[0], axis=0)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, truncated, info = env.step(int(action))\n",
    "        #time.sleep(0.01)\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode+1, total_reward))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
